{"metadata":{"colab":{"collapsed_sections":["gK4w58xDWBYE","tvm5O58UnEXc","Jjbm3dyUX6Hg","t5Sq9OIhTOhj","7yo0z47isHOG","ZdKpQxnq2zlm"],"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install boto3\n!pip install botocore","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwumNf5A9IkX","outputId":"142c4845-e1c0-4cfe-843c-cfc42d501595","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom prettytable import PrettyTable\nimport shutil\nimport tensorflow as tf\nimport random\nfrom PIL import Image\nimport boto3\nfrom botocore.exceptions import ClientError\n# from google.colab import userdata\nimport os\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()","metadata":{"id":"QK399-xB59Rd","execution":{"iopub.status.busy":"2024-05-22T09:43:09.872710Z","iopub.execute_input":"2024-05-22T09:43:09.873054Z","iopub.status.idle":"2024-05-22T09:43:14.547609Z","shell.execute_reply.started":"2024-05-22T09:43:09.873028Z","shell.execute_reply":"2024-05-22T09:43:14.546613Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-22 09:43:11.181863: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-22 09:43:11.181916: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-22 09:43:11.183638: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w0XrC2n0MeM2","outputId":"ffb003e1-93f4-4742-9f5d-d74149ea227f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Notebook Initialization","metadata":{"id":"yGwUe-gU5-_y"}},{"cell_type":"markdown","source":"## Some constant","metadata":{"id":"RobVxP_NkJj8"}},{"cell_type":"code","source":"# !rm -rf \"/content/drive/MyDrive/written_number_classifier\"","metadata":{"id":"5nqeITPEmYW-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# constants to hold access key and id using environment variables\n\naws_access_key_id =  user_secrets.get_secret(\"AWS_ACCESS_KEY_ID\")\naws_secret_access_key = user_secrets.get_secret(\"AWS_SECRET_ACCESS_KEY\")\n\n# Create an S3 resource with explicit credentials if provided\ns3_resource = boto3.resource(\n    's3', aws_access_key_id=aws_access_key_id,\n    aws_secret_access_key=aws_secret_access_key\n    )","metadata":{"id":"7qW7re9sgQJj","execution":{"iopub.status.busy":"2024-05-22T11:12:57.837077Z","iopub.execute_input":"2024-05-22T11:12:57.837827Z","iopub.status.idle":"2024-05-22T11:12:59.327909Z","shell.execute_reply.started":"2024-05-22T11:12:57.837791Z","shell.execute_reply":"2024-05-22T11:12:59.327076Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '/content/drive/MyDrive/written_number_classifier'\nDATA_SOURCE_DIR = os.path.join(ROOT_DIR,'Data_source')\nDATAZIP_PATH = '/content/drive/MyDrive/data.zip'\nPREDICTION_DATA_DIR = os.path.join(ROOT_DIR,'prediction_data')\nBAD_IMAGE_DIR = os.path.join(ROOT_DIR,'bad_images')\nRAW_IMAGES_STATISTICS = os.path.join(ROOT_DIR,'image_stats/stat.csv')\n\nos.makedirs(ROOT_DIR,exist_ok=True)\n\nROOT_ARTIFACT = os.path.join(ROOT_DIR,\"artifacts\")\nTRAIN_DATA_ARTIFACT = os.path.join(ROOT_ARTIFACT,'feature_store/train')\nVALIDATION_DATA_ARTIFACT = os.path.join(ROOT_ARTIFACT,'feature_store/validation')\nTEST_DATA_ARTIFACT = os.path.join(ROOT_ARTIFACT,'feature_store/test')\nPREPROCESSED_IMAGES_STATISTICS = os.path.join(ROOT_ARTIFACT,'train_image_stats/stat.csv')\nDATA_ARTIFACT_ZIP = 'data_artifact.zip'","metadata":{"id":"rNjPT-sbkM60","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"J2W1_Q2OtIDK"}},{"cell_type":"markdown","source":"## Some important functions and classes","metadata":{"id":"E-3Ll-wfj3Q0"}},{"cell_type":"markdown","source":"### Class to analyze images","metadata":{"id":"gK4w58xDWBYE"}},{"cell_type":"code","source":"class ImageDataAnalyzer:\n    def __init__(self, image_df):\n        \"\"\"\n        Initialize the ImageDataAnalyzer with a DataFrame containing image statistics.\n\n        Parameters:\n        - image_df (DataFrame): DataFrame containing image statistics.\n        \"\"\"\n        self.image_df = image_df\n        sns.set(style='whitegrid', palette='muted')\n\n    def display_section_heading(self, heading):\n        \"\"\"\n        Display a formatted section heading.\n\n        Parameters:\n        - heading (str): The heading text.\n\n        Returns:\n        - None\n        \"\"\"\n        print(\"\\n\" + \"-\"*80 + f\" {heading} \" + \"-\"*80+ \"\\n\")\n\n\n    def calculate_total_image_statistics(self):\n        \"\"\"\n        Calculate and display total image statistics.\n\n        Returns:\n        - None\n        \"\"\"\n        total_images = len(self.image_df)\n        max_images_label = self.image_df['Label'].value_counts().idxmax()\n        max_images_count = self.image_df['Label'].value_counts().max()\n        min_images_label = self.image_df['Label'].value_counts().idxmin()\n        min_images_count = self.image_df['Label'].value_counts().min()\n        median_images_count = np.median(self.image_df['Label'].value_counts())\n\n        median_height = self.image_df['Height'].median()\n        median_width = self.image_df['Width'].median()\n        max_height = self.image_df['Height'].max()\n        max_height_label = self.image_df.loc[self.image_df['Height'].idxmax(), 'Label']\n        max_width = self.image_df['Width'].max()\n        max_width_label = self.image_df.loc[self.image_df['Width'].idxmax(), 'Label']\n        min_height = self.image_df['Height'].min()\n        min_height_label = self.image_df.loc[self.image_df['Height'].idxmin(), 'Label']\n        min_width = self.image_df['Width'].min()\n        min_width_label = self.image_df.loc[self.image_df['Width'].idxmin(), 'Label']\n\n        self.display_section_heading(\"Total Number of Images Statistics\")\n\n        total_images_table = PrettyTable(['Statistic', 'Value'])\n        total_images_table.add_row(['Total Number of Images', f'{total_images}'])\n        total_images_table.add_row(['Label with Max Images', f'{max_images_label}: {max_images_count}'])\n        total_images_table.add_row(['Label with Min Images', f'{min_images_label}: {min_images_count}'])\n        total_images_table.add_row(['Median Number of Images', f'{median_images_count:.2f}'])\n        total_images_table.add_row(['Median Height', f'{median_height:.2f}'])\n        total_images_table.add_row(['Median Width', f'{median_width:.2f}'])\n        total_images_table.add_row(['Max Height', f'{max_height:.2f} ({max_height_label})'])\n        total_images_table.add_row(['Max Width', f'{max_width:.2f} ({max_width_label})'])\n        total_images_table.add_row(['Min Height', f'{min_height:.2f} ({min_height_label})'])\n        total_images_table.add_row(['Min Width', f'{min_width:.2f} ({min_width_label})'])\n\n        print(total_images_table)\n        print()\n\n    def plot_image_statistics(self):\n        \"\"\"\n        Plot the distribution of number of pixels, file sizes, heights, and widths.\n\n        Returns:\n        - None\n        \"\"\"\n        self.display_section_heading(\"Image Statistics Distribution\")\n\n        plt.figure(figsize=(16, 12))\n\n        plt.subplot(2, 2, 1)\n        sns.histplot(data=self.image_df, x='NumPixels', bins=30, kde=True, color='skyblue')\n        plt.title('Distribution of Number of Pixels')\n        plt.xlabel('Number of Pixels')\n        plt.ylabel('Frequency')\n\n        plt.subplot(2, 2, 2)\n        sns.histplot(data=self.image_df, x='FileSizeIn_kb', bins=30, kde=True, color='salmon')\n        plt.title('Distribution of File Sizes')\n        plt.xlabel('File Size (KB)')\n        plt.ylabel('Frequency')\n\n        plt.subplot(2, 2, 3)\n        sns.histplot(data=self.image_df, x='Width', bins=30, kde=True, color='lightgreen')\n        plt.title('Distribution of Widths')\n        plt.xlabel('Width (pixels)')\n        plt.ylabel('Frequency')\n\n        plt.subplot(2, 2, 4)\n        sns.histplot(data=self.image_df, x='Height', bins=30, kde=True, color='lightcoral')\n        plt.title('Distribution of Heights')\n        plt.xlabel('Height (pixels)')\n        plt.ylabel('Frequency')\n\n        plt.tight_layout()\n        plt.show()\n\n    def boxplot_number_images_per_label(self):\n        \"\"\"\n        Calculate and plot the number of images per label.\n\n        Returns:\n        - None\n        \"\"\"\n        self.display_section_heading(\"Number of Images per Label\")\n\n        label_counts = self.image_df['Label'].value_counts()\n\n\n        plt.figure(figsize=(12, 6))\n        sns.boxplot(x=label_counts.index, y=label_counts.values, palette='viridis')\n        plt.title('Number of Images per Label')\n        plt.xlabel('Label')\n        plt.ylabel('Count')\n        plt.xticks(rotation=90)\n        plt.tight_layout()\n        plt.show()\n\n    def calculate_label_wise_statistics(self):\n        \"\"\"\n        Calculate and display label-wise image statistics.\n\n        Returns:\n        - None\n        \"\"\"\n        label_stats = self.image_df.groupby('Label').agg({\n            'Width': ['mean', 'median', 'min', 'max'],\n            'Height': ['mean', 'median', 'min', 'max'],\n            'NumPixels':['mean', 'median', 'min', 'max'],\n            'FileSizeIn_kb': ['mean', 'median', 'min', 'max'],\n            'Label': 'size'\n        })\n        label_stats.columns = ['Mean Width', 'Median Width', 'Min Width', 'Max Width',\n                               'Mean Height', 'Median Height', 'Min Height', 'Max Height',\n                               'Mean Pixels', 'Median Pixels', 'Min Pixels', 'Max Pixels',\n                               'Mean File Size (KB)', 'Median File Size (KB)', 'Min File Size (KB)', 'Max File Size (KB)',\n                               'Count']\n\n        self.display_section_heading(\"Label-wise Image Statistics\")\n\n        label_stats_table = PrettyTable(['Label', 'Mean Width', 'Median Width', 'Min Width', 'Max Width',\n                                         'Mean Height', 'Median Height', 'Min Height', 'Max Height',\n                                         'Mean Pixels', 'Median Pixels', 'Min Pixels', 'Max Pixels',\n                                        'Mean File Size (KB)', 'Median File Size (KB)', 'Min File Size (KB)', 'Max File Size (KB)',\n                                        'Count'])\n\n        for index, row in label_stats.iterrows():\n            label_stats_table.add_row([index,f\"{row['Mean Width']:.2f}\", f\"{row['Median Width']:.2f}\",\n                                       f\"{row['Min Width']:.2f}\", f\"{row['Max Width']:.2f}\",\n                                       f\"{row['Mean Height']:.2f}\", f\"{row['Median Height']:.2f}\",\n                                       f\"{row['Min Height']:.2f}\", f\"{row['Max Height']:.2f}\",\n                                       f\"{row['Mean Pixels']:.2f}\", f\"{row['Median Pixels']:.2f}\",\n                                       f\"{row['Min Pixels']:.2f}\", f\"{row['Max Pixels']:.2f}\",\n                                       f\"{row['Mean File Size (KB)']:.2f}\", f\"{row['Median File Size (KB)']:.2f}\",\n                                       f\"{row['Min File Size (KB)']:.2f}\", f\"{row['Max File Size (KB)']:.2f}\",\n                                       f\"{row['Count']}\"])\n\n        print(label_stats_table)\n\n\n\n    def analyze(self):\n        \"\"\"\n        Perform the complete analysis by calling all the required methods.\n\n        Returns:\n        - None\n        \"\"\"\n        self.plot_image_statistics()\n        # self.boxplot_number_images_per_label()\n        self.calculate_label_wise_statistics()\n        self.calculate_total_image_statistics()\n","metadata":{"id":"ZHiw9QLWV598"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Functions","metadata":{"id":"igTMbSaCWSeb"}},{"cell_type":"code","source":"\n\n#######################################################################################################################################\n\n\ndef move_random_files(source_dir, dest_dir, percentage=20):\n    \"\"\"\n    Moves a specified percentage of files from the source directory to the destination directory.\n    If percentage is 100, copies all content from the source directory to the destination directory.\n\n    Parameters:\n    - source_dir (str): The path to the main directory containing the labeled subdirectories.\n    - dest_dir (str): The path to the directory where the selected files will be moved.\n    - percentage (int): The percentage of files to move. Default is 20%.\n    \"\"\"\n    # Check if the destination directory is empty\n    if os.listdir(dest_dir):\n        print(\"Destination directory is not empty. Operation aborted.\")\n        return\n\n    # Create destination folder if it doesn't exist\n    os.makedirs(dest_dir, exist_ok=True)\n\n    # If the percentage is 100, copy all contents from source_dir to dest_dir\n    if percentage == 100:\n        for item in os.listdir(source_dir):\n            item_path = os.path.join(source_dir, item)\n            if os.path.isdir(item_path):\n                shutil.copytree(item_path, os.path.join(dest_dir, item), dirs_exist_ok=True)\n            # else:\n            #     shutil.copy2(item_path, dest_dir)\n        print(\"All contents copied to destination directory.\")\n        return\n\n    # Traverse the main directory to move files from each class directory\n    for label in os.listdir(source_dir):\n        label_path = os.path.join(source_dir, label)\n        if os.path.isdir(label_path):\n            # Create destination class directory\n            dest_label_path = os.path.join(dest_dir, label)\n            os.makedirs(dest_label_path, exist_ok=True)\n\n            # Collect file paths from the current class directory\n            file_paths = [os.path.join(label_path, file) for file in os.listdir(label_path)]\n\n            # Shuffle the file paths randomly\n            random.shuffle(file_paths)\n\n            # Calculate the number of files to move\n            num_to_move = int(len(file_paths) * (percentage / 100))\n\n            # Move the selected files to the destination class directory\n            for file in file_paths[:num_to_move]:\n                dest_file_path = os.path.join(dest_label_path, os.path.basename(file))\n                shutil.move(file, dest_file_path)\n\n    print(\"Files moved successfully.\")\n\n##################################################################################################################################\n\n\ndef preprocessing(source_dir):\n    \"\"\"\n    Processes all images in class folders within the source directory. Resizes and converts images to grayscale,\n    then saves them back to their original locations.\n\n    Parameters:\n    - source_dir (str): The path to the main directory containing class subdirectories with images.\n    \"\"\"\n    # Traverse the source directory\n    for class_folder in os.listdir(source_dir):\n        class_folder_path = os.path.join(source_dir, class_folder)\n        if os.path.isdir(class_folder_path):\n            # Process each image in the class folder\n            for filename in os.listdir(class_folder_path):\n                image_path = os.path.join(class_folder_path, filename)\n\n                # Load the image\n                image = tf.keras.utils.load_img(\n                    path=image_path,\n                    color_mode='grayscale',\n                    target_size=(250, 250),\n                    interpolation='nearest'\n                    )\n                image.save(image_path)\n\n####################################################################################################################################\n\n\ndef augmentation(source_dir):\n\n    \"\"\"\n    Balance each class by augmenting the images up to 20 images per class.\n\n    Args:\n    - source_dir (str): Path to the source directory containing class folders.\n    - max_images_per_class (int): Maximum number of images per class after augmentation.\n\n    Returns:\n    None\n    \"\"\"\n\n    # List of TensorFlow random augmentation functions\n    random_augmentation_functions = [\n    lambda image: tf.image.stateless_random_brightness(image=image, seed=(1,2), max_delta=0.3),\n    lambda image: tf.image.stateless_random_contrast(image=image, seed=(1,2), lower=0.2, upper=0.5),\n    lambda image: tf.image.flip_left_right(image=image),\n    lambda image: tf.image.flip_up_down(image=image),\n    lambda image: tf.image.rot90(image, k=1),\n    ]\n\n    # Traverse the source directory\n    for class_folder in os.listdir(source_dir):\n        class_folder_path = os.path.join(source_dir, class_folder)\n        if os.path.isdir(class_folder_path):\n            for images in os.listdir(class_folder_path):\n                img_path = os.path.join(class_folder_path,images)\n                image = tf.keras.utils.load_img(\n                    path=img_path,\n                    color_mode='rgb',\n                    target_size=(300, 300,3),\n                    interpolation='nearest'\n                    )\n                image=tf.keras.preprocessing.image.img_to_array(image)\n\n                # Apply random augmentation\n                for i in range(2):\n                    choice = random.randint(0,len(random_augmentation_functions)-1)\n                    augmented_image = random_augmentation_functions[choice](image)\n                    augmented_image=tf.cast(augmented_image, tf.uint8)\n\n                    # Convert image back to uint8 and save as PNG in the same directory\n                    augmented_image = Image.fromarray(augmented_image.numpy().reshape(300,300,3))\n                    augmented_img_path = os.path.join(class_folder_path, f\"aug{i}_{images}\")\n                    augmented_image.save(augmented_img_path)\n\n                print(f\"Augmented and saved image: {augmented_img_path}\")\n\n\n#############################################################################################################################################################\n\n\ndef gather_image_statistics(main_dir, output_dir, bad_images_dir):\n    \"\"\"\n    Gather statistics for images in the specified directory.\n\n    Args:\n    - main_dir (str): Path to the main directory containing class folders.\n    - output_dir (str): Path to the directory where the CSV file with statistics will be saved.\n    - bad_images_dir (str): Path to the directory where bad images will be moved.\n\n    Returns:\n    None\n    \"\"\"\n    image_data = []\n\n    # Traverse the main directory to gather statistics\n    for label in os.listdir(main_dir):\n        label_path = os.path.join(main_dir, label)\n        if os.path.isdir(label_path):  # Ensure it's a directory\n            label_images = [img for img in os.listdir(label_path)]\n\n            # Gather image statistics\n            for i, img_file in enumerate(label_images):\n                img_path = os.path.join(label_path, img_file)\n                try:\n                    with Image.open(img_path) as img:\n                        width, height = img.size\n                        num_pixels = width * height\n                        file_size = os.path.getsize(img_path) / 1000  # Size in kilobytes\n                        image_data.append({\n                            'Label': label,\n                            'Filename': img_file,\n                            'Width': width,\n                            'Height': height,\n                            'NumPixels': num_pixels,\n                            'FileSizeIn_kb': file_size\n                        })\n                except Exception as e:\n                    print(f\"Error processing {img_path}: {e}\")\n                    # Move the rejected file to the bad images folder\n                    # os.makedirs(bad_images_dir, exist_ok=True)\n                    # dest_path = os.path.join(bad_images_dir, f'{label}_{img_file}')\n                    # os.rename(img_path, dest_path)\n\n        print(\"work in progress...\")\n\n    # Create a DataFrame\n    image_df = pd.DataFrame(image_data)\n\n    # Display the statistics\n    print(\"DataFrame with image statistics:\")\n    print(image_df.head())\n\n    # Create the directory to save image statistics CSV if it doesn't exist\n\n    os.makedirs(os.path.dirname(output_dir), exist_ok=True)\n\n    # Save the DataFrame to a CSV file\n    image_df.to_csv(output_dir, index=False)\n\n##########################################################################################################################################\n\nimport zipfile\nimport os\n\ndef unzip_folder(zip_path, dest_folder):\n    \"\"\"\n    Unzips a folder to a destination folder.\n\n    Args:\n        zip_path: Path to the ZIP file.\n        dest_folder: Path to the destination folder.\n\n    Returns:\n        None\n    \"\"\"\n    # Ensure the ZIP file exists\n    if not os.path.exists(zip_path):\n        print(f\"Error: ZIP file '{zip_path}' not found.\")\n        return\n\n    # Ensure the destination folder path is absolute\n    dest_folder = os.path.abspath(dest_folder)\n\n    # Create the destination folder if it doesn't exist\n    os.makedirs(dest_folder, exist_ok=True)\n\n    # Unzip the ZIP file\n    with zipfile.ZipFile(zip_path, 'r') as zipf:\n        zipf.extractall(dest_folder)\n\n    print(f\"ZIP file '{zip_path}' unzipped successfully to '{dest_folder}'.\")\n\n############################################################################################################################\n\ndef upload_file_to_s3( s3_resource,bucket_name,local_path,s3_path):\n    bucket = s3_resource.Bucket(bucket_name)\n    try:\n        bucket.upload_file(local_path, s3_path)\n        print(f'Successfully uploaded {local_path} to s3://{bucket.name}/{s3_path}')\n    except FileNotFoundError:\n        print(f'The file was not found: {local_path}')\n    except boto3.exceptions.S3UploadFailedError as e:\n        print(f'Failed to upload {local_path} to {s3_path}: {e}')\n\n####################################################################################################################################\n\nimport boto3\n\ndef upload_file_to_s3(file_name,s3_resource, bucket_name, object_name=None):\n    \"\"\"\n    Upload a file to an S3 bucket\n\n    :param file_name: File to upload\n    :param bucket_name: Bucket to upload to\n    :param object_name: S3 object name. If not specified then file_name is used\n    :return: True if file was uploaded, else False\n    \"\"\"\n    # If S3 object_name was not specified, use file_name\n    if object_name is None:\n        object_name = file_name\n\n    # Upload the file\n    try:\n        s3_resource.Bucket(bucket_name).upload_file(file_name, object_name)\n        print(f\"File {file_name} uploaded to {bucket_name}/{object_name}\")\n        return True\n    except Exception as e:\n        print(f\"Error uploading file: {e}\")\n        return False\n\n\n\n######################################################################################################################################\n\ndef upload_directory_to_s3(local_directory, s3_resource, bucket_name, s3_directory):\n    bucket = s3_resource.Bucket(bucket_name)\n\n    # Collect all files to upload\n    files_to_upload = []\n    for root, dirs, files in os.walk(local_directory):\n        for file in files:\n            local_path = os.path.join(root, file)\n            relative_path = os.path.relpath(local_path, local_directory)\n            s3_path = os.path.join(s3_directory, relative_path).replace(\"\\\\\", \"/\")\n            files_to_upload.append((local_path, s3_path))\n\n    # Use ThreadPoolExecutor for concurrent uploading\n    with ThreadPoolExecutor() as executor:\n        futures = []\n        for local_path, s3_path in files_to_upload:\n            futures.append(executor.submit(upload_file, local_path, bucket, s3_path))\n\n        # Process results\n        for future in as_completed(futures):\n            try:\n                future.result()\n            except Exception as e:\n                print(f'An error occurred: {e}')\n#######################################################################################################################\n\nimport os\nimport zipfile\n\ndef zip_directory(directory_path, zip_file_path):\n    \"\"\"\n    Zip a directory recursively.\n\n    Args:\n    - directory_path: Path to the directory to be zipped.\n    - zip_file_path: Path to the resulting zip file.\n\n    Returns:\n    - True if zipping was successful, False otherwise.\n    \"\"\"\n    try:\n        with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            for root, dirs, files in os.walk(directory_path):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    zipf.write(file_path, os.path.relpath(file_path, directory_path))\n\n        print(f\"Directory zipped successfully. Zip file saved at: {zip_file_path}\")\n        return True\n    except Exception as e:\n        print(f\"Error zipping directory: {e}\")\n        return False\n\n###############################################################################################################\n\n\n\ndef download_directory_from_s3(s3_resource, bucket_name, s3_directory, local_directory):\n    \"\"\"\n    Download a directory from S3 to a local directory recursively using Boto3 Resource.\n\n    Args:\n    - s3_resource: Boto3 S3 Resource.\n    - bucket_name: Name of the S3 bucket.\n    - s3_directory: Directory (prefix) in S3 to download.\n    - local_directory: Local directory to download files to.\n    \"\"\"\n\n    # Create the local directory if it doesn't exist\n    os.makedirs(local_directory, exist_ok=True)\n\n    # S3 bucket object\n    bucket = s3_resource.Bucket(bucket_name)\n\n    # List all objects in the S3 directory\n    for obj in bucket.objects.filter(Prefix=s3_directory):\n        # Construct the local file path\n        local_file_path = os.path.join(local_directory, os.path.relpath(obj.key, s3_directory))\n\n        # Create the local directory if it doesn't exist\n        os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n\n        # Download the file from S3\n        bucket.download_file(obj.key, local_file_path)\n\n        print(f\"Downloaded {obj.key} to {local_file_path}\")\n\n    print(f\"Download of directory {s3_directory} complete.\")\n\n\n#################################################################################################################################\n\n\ndef download_file_from_s3(s3_resource,bucket_name, object_name, file_name):\n    \"\"\"\n    Download a file from an S3 bucket\n\n    :param bucket_name: Name of the S3 bucket\n    :param object_name: Name of the object in S3\n    :param file_name: Name of the file to save as locally\n    :return: True if file was downloaded, else False\n    \"\"\"\n\n    # Download the file\n    try:\n        s3_resource.Bucket(bucket_name).download_file(object_name, file_name)\n        print(f\"File {object_name} from bucket {bucket_name} downloaded as {file_name}\")\n        return True\n    except Exception as e:\n        print(f\"Error downloading file: {e}\")\n        return False","metadata":{"id":"HhztV4RNj2nF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3927db77-9bbf-4211-c02f-04e30a467ade","execution":{"iopub.status.busy":"2024-05-22T11:12:23.267595Z","iopub.execute_input":"2024-05-22T11:12:23.267956Z","iopub.status.idle":"2024-05-22T11:12:23.315249Z","shell.execute_reply.started":"2024-05-22T11:12:23.267929Z","shell.execute_reply":"2024-05-22T11:12:23.314247Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# Data Ingestion Workflow","metadata":{"id":"tvm5O58UnEXc"}},{"cell_type":"markdown","source":"## Unzipping data and saving it to destination folder","metadata":{"id":"-4B3prQZgs8i"}},{"cell_type":"code","source":"!rm -rf /content/Data_source","metadata":{"id":"_yqQuP0Khqhx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unzip_folder(zip_path=DATAZIP_PATH,\n             dest_folder=ROOT_DIR\n             )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wNrM2pG4gdCy","outputId":"ffeac26b-7c62-4916-a74b-835acb528b14"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Studing image statistics","metadata":{"id":"Jjbm3dyUX6Hg"}},{"cell_type":"code","source":"# getting image stat of train data\ngather_image_statistics(main_dir=DATA_SOURCE_DIR,\n                        output_dir=RAW_IMAGES_STATISTICS,\n                        bad_images_dir=BAD_IMAGE_DIR)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vXDISHyNnhK","outputId":"25397b31-9f4b-4059-89cf-4c1501069803"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(RAW_IMAGES_STATISTICS)\ndf","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"nyCfEcEhSRKE","outputId":"044d6667-10ee-4b6c-e55c-642047a973bb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ImageDataAnalyzer(df).analyze()","metadata":{"id":"8poO43z63sGp","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"400247a9-1141-481e-c469-1cda363fa5f9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Spliting train and validation Preprocessing and augemneting images and save it as artifact","metadata":{"id":"t5Sq9OIhTOhj"}},{"cell_type":"code","source":"!rm -rf /content/drive/MyDrive/written_number_classifier/artifacts","metadata":{"id":"cYUWAVuhcnYh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create atifact folder if not present\nos.makedirs(TRAIN_DATA_ARTIFACT,exist_ok=True)\nos.makedirs(VALIDATION_DATA_ARTIFACT,exist_ok=True)\nos.makedirs(TEST_DATA_ARTIFACT,exist_ok=True)","metadata":{"id":"VvICJnmSPoUj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# copying all contents of From data source to train data artifact\nmove_random_files(source_dir=DATA_SOURCE_DIR , dest_dir=TRAIN_DATA_ARTIFACT, percentage=100)\n\n# moving 20 percent of train data for validation\nmove_random_files(source_dir=TRAIN_DATA_ARTIFACT, dest_dir=VALIDATION_DATA_ARTIFACT, percentage=20)\n\n# moving 20 percent of train data for prediction/ TEST\nmove_random_files(source_dir=TRAIN_DATA_ARTIFACT, dest_dir=TEST_DATA_ARTIFACT, percentage=20)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7pijCaRW0g-","outputId":"161e0291-ca43-48a4-8f47-324ed88d3940"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Augmenting train data\naugmentation(source_dir=TRAIN_DATA_ARTIFACT)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GxrDTMZEJltv","outputId":"e4141a82-e620-4b09-d11c-0dd023ea0e4e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Analysing prepocessed and augmented train images","metadata":{"id":"7yo0z47isHOG"}},{"cell_type":"code","source":"# getting image stat of train data\ngather_image_statistics(main_dir=TRAIN_DATA_ARTIFACT,\n                        output_dir=PREPROCESSED_IMAGES_STATISTICS,\n                        bad_images_dir='')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cb-RDn37sd0F","outputId":"8d17b79b-4d61-46c8-f471-d5cbcd754378"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(PREPROCESSED_IMAGES_STATISTICS)\ndf","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"8Mv6pk9twCzi","outputId":"e703fe0b-6e18-4748-943d-75c5f86c5c66"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ImageDataAnalyzer(df).analyze()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DOXgf7UwyFta","outputId":"eceb4748-ae6c-46e1-cd6a-bceeb4a8421a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Zipping and uploading artifacts to s3 for later use\n\n","metadata":{"id":"aoCEHzZj_6hY"}},{"cell_type":"code","source":"# zipping the artifact\nzip_directory(directory_path =ROOT_ARTIFACT,\n              zip_file_path=DATA_ARTIFACT_ZIP)\n","metadata":{"id":"UYslQUXMPAQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"upload_file_to_s3(\n    local_path=DATA_ARTIFACT_ZIP,\n    bucket_name='written-number-classifier',\n    s3_path='artifact/data_artifact/data_artifact.zip',\n    s3_resource=s3_resource\n    )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TYwZeD1m34E","outputId":"9abb7cfc-28c7-46da-dc63-e4a3f43ef066"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training work Flow","metadata":{"id":"awwdPMz0mkcE"}},{"cell_type":"code","source":"!rm -rf /content/drive/MyDrive/written_number_classifier","metadata":{"id":"D5DPQVNr1ByC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/artifacts/model/working.model.keras","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Some constants related to training workflow","metadata":{"id":"z7TIIvOJ2eNw"}},{"cell_type":"markdown","source":"## Download data artifact zip and unzipping it for training phase","metadata":{"id":"ZdKpQxnq2zlm"}},{"cell_type":"code","source":"# downloading data artifact zip\ndownload_file_from_s3(\n    s3_resource,\n    'written-number-classifier',\n    'artifact/data_artifact/data_artifact.zip',\n    DATA_ARTIFACT_ZIP\n    )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VeR___hfz423","outputId":"9455118f-0a15-4960-b37b-aad5e23045b6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unzipping data artifacr zip\nunzip_folder(DATA_ARTIFACT_ZIP,'')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FR4url7Wz30e","outputId":"1ef67605-e750-4fb4-87f8-0c769cdcd18f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Converting the images to tf.data.dataset for training","metadata":{"id":"mH3MF-EIhxaT"}},{"cell_type":"code","source":"train_ds = tf.keras.utils.image_dataset_from_directory(\n    TRAIN_DATA_ARTIFACT,\n    seed=123,\n    batch_size=128,\n    color_mode=\"grayscale\",\n    image_size=(256, 256),\n    shuffle=True,\n    # validation_split=0.3,\n    # subset='training',\n  )\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    VALIDATION_DATA_ARTIFACT,\n    seed=123,\n    batch_size=128,\n    color_mode=\"grayscale\",\n    image_size=(256, 256),\n    shuffle=True,\n    # validation_split=0.3,\n    # subset='validation'\n  )\n\n# train_ds.save(TRAIN_DATA_ARTIFACT)\n# val_ds.save(VALIDATION_DATA_ARTIFACT)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Em7TXb3mfLIH","outputId":"98b79f23-c123-4e76-dfc6-de5bb38bc1dc","execution":{"iopub.status.busy":"2024-05-22T10:08:08.841761Z","iopub.execute_input":"2024-05-22T10:08:08.842492Z","iopub.status.idle":"2024-05-22T10:08:12.221777Z","shell.execute_reply.started":"2024-05-22T10:08:08.842460Z","shell.execute_reply":"2024-05-22T10:08:12.221017Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Found 19200 files belonging to 100 classes.\nFound 2000 files belonging to 100 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:08:24.726583Z","iopub.execute_input":"2024-05-22T10:08:24.726966Z","iopub.status.idle":"2024-05-22T10:08:24.732386Z","shell.execute_reply.started":"2024-05-22T10:08:24.726938Z","shell.execute_reply":"2024-05-22T10:08:24.731384Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"['eight', 'eighteen', 'eighty', 'eighty eight', 'eighty five', 'eighty four', 'eighty nine', 'eighty one', 'eighty seven', 'eighty six', 'eighty three', 'eighty two', 'eleven', 'fifteen', 'fifty', 'fifty eight', 'fifty five', 'fifty four', 'fifty nine', 'fifty one', 'fifty seven', 'fifty six', 'fifty three', 'fifty two', 'five', 'forty', 'forty eight', 'forty five', 'forty four', 'forty nine', 'forty one', 'forty seven', 'forty six', 'forty three', 'forty two', 'four', 'fourteen', 'hundred', 'nine', 'nineteen', 'ninety', 'ninety eight', 'ninety five', 'ninety four', 'ninety nine', 'ninety one', 'ninety seven', 'ninety six', 'ninety three', 'ninety two', 'one', 'seven', 'seventeen', 'seventy', 'seventy eight', 'seventy five', 'seventy four', 'seventy nine', 'seventy one', 'seventy seven', 'seventy six', 'seventy three', 'seventy two', 'six', 'sixteen', 'sixty', 'sixty eight', 'sixty five', 'sixty four', 'sixty nine', 'sixty one', 'sixty seven', 'sixty six', 'sixty three', 'sixty two', 'ten', 'thirteen', 'thirty', 'thirty eight', 'thirty five', 'thirty four', 'thirty nine', 'thirty one', 'thirty seven', 'thirty six', 'thirty three', 'thirty two', 'three', 'twelve', 'twenty', 'twenty eight', 'twenty five', 'twenty four', 'twenty nine', 'twenty one', 'twenty seven', 'twenty six', 'twenty three', 'twenty two', 'two']\n","output_type":"stream"}]},{"cell_type":"code","source":"save_class_labels(class_names, LABEL_ARTIFACT)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:27:46.458651Z","iopub.execute_input":"2024-05-22T10:27:46.459671Z","iopub.status.idle":"2024-05-22T10:27:46.464672Z","shell.execute_reply.started":"2024-05-22T10:27:46.459635Z","shell.execute_reply":"2024-05-22T10:27:46.463616Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import json\n\ndef save_class_labels(lst, filename):\n    \"\"\"\n    Serialize a list of class labels into a JSON file.\n\n    Args:\n        lst (list): The list of class labels.\n        filename (str): The filename for the JSON file.\n\n    Returns:\n        None\n    \"\"\"\n    # Creating the mapped dictionary\n    mapped_dict = {i: lst[i] for i in range(len(lst))}\n    \n    \n    os.makedirs(os.path.dirname(filename),exist_ok = True)\n    \n    # Serialize the dictionary to JSON\n    with open(filename, 'w') as f:\n        json.dump(mapped_dict, f)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:30:15.440697Z","iopub.execute_input":"2024-05-22T10:30:15.441159Z","iopub.status.idle":"2024-05-22T10:30:15.450903Z","shell.execute_reply.started":"2024-05-22T10:30:15.441107Z","shell.execute_reply":"2024-05-22T10:30:15.448795Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import json\n\ndef read_class_labels(filename):\n    \"\"\"\n    Read class labels from a JSON file.\n\n    Args:\n        filename (str): The filename of the JSON file.\n\n    Returns:\n        dict: A dictionary containing the class labels.\n    \"\"\"\n    with open(filename, 'r') as f:\n        class_labels = json.load(f)\n    return class_labels\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:30:23.360688Z","iopub.execute_input":"2024-05-22T10:30:23.361092Z","iopub.status.idle":"2024-05-22T10:30:23.367001Z","shell.execute_reply.started":"2024-05-22T10:30:23.361059Z","shell.execute_reply":"2024-05-22T10:30:23.365835Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Example usage\nclass_labels = read_class_labels(LABEL_ARTIFACT)\nprint(class_labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:32:43.628916Z","iopub.execute_input":"2024-05-22T10:32:43.629851Z","iopub.status.idle":"2024-05-22T10:32:43.635539Z","shell.execute_reply.started":"2024-05-22T10:32:43.629817Z","shell.execute_reply":"2024-05-22T10:32:43.634545Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"{'0': 'eight', '1': 'eighteen', '2': 'eighty', '3': 'eighty eight', '4': 'eighty five', '5': 'eighty four', '6': 'eighty nine', '7': 'eighty one', '8': 'eighty seven', '9': 'eighty six', '10': 'eighty three', '11': 'eighty two', '12': 'eleven', '13': 'fifteen', '14': 'fifty', '15': 'fifty eight', '16': 'fifty five', '17': 'fifty four', '18': 'fifty nine', '19': 'fifty one', '20': 'fifty seven', '21': 'fifty six', '22': 'fifty three', '23': 'fifty two', '24': 'five', '25': 'forty', '26': 'forty eight', '27': 'forty five', '28': 'forty four', '29': 'forty nine', '30': 'forty one', '31': 'forty seven', '32': 'forty six', '33': 'forty three', '34': 'forty two', '35': 'four', '36': 'fourteen', '37': 'hundred', '38': 'nine', '39': 'nineteen', '40': 'ninety', '41': 'ninety eight', '42': 'ninety five', '43': 'ninety four', '44': 'ninety nine', '45': 'ninety one', '46': 'ninety seven', '47': 'ninety six', '48': 'ninety three', '49': 'ninety two', '50': 'one', '51': 'seven', '52': 'seventeen', '53': 'seventy', '54': 'seventy eight', '55': 'seventy five', '56': 'seventy four', '57': 'seventy nine', '58': 'seventy one', '59': 'seventy seven', '60': 'seventy six', '61': 'seventy three', '62': 'seventy two', '63': 'six', '64': 'sixteen', '65': 'sixty', '66': 'sixty eight', '67': 'sixty five', '68': 'sixty four', '69': 'sixty nine', '70': 'sixty one', '71': 'sixty seven', '72': 'sixty six', '73': 'sixty three', '74': 'sixty two', '75': 'ten', '76': 'thirteen', '77': 'thirty', '78': 'thirty eight', '79': 'thirty five', '80': 'thirty four', '81': 'thirty nine', '82': 'thirty one', '83': 'thirty seven', '84': 'thirty six', '85': 'thirty three', '86': 'thirty two', '87': 'three', '88': 'twelve', '89': 'twenty', '90': 'twenty eight', '91': 'twenty five', '92': 'twenty four', '93': 'twenty nine', '94': 'twenty one', '95': 'twenty seven', '96': 'twenty six', '97': 'twenty three', '98': 'twenty two', '99': 'two'}\n","output_type":"stream"}]},{"cell_type":"code","source":"# pushing the labbel to S3\nupload_file_to_s3(file_name=LABEL_ARTIFACT,\n                  s3_resource=s3_resource,\n                  bucket_name='written-number-classifier',\n                  object_name=S3_LABEL_ARTIFACT_PATH\n                  )","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:21:06.589275Z","iopub.execute_input":"2024-05-22T11:21:06.590224Z","iopub.status.idle":"2024-05-22T11:21:07.001632Z","shell.execute_reply.started":"2024-05-22T11:21:06.590184Z","shell.execute_reply":"2024-05-22T11:21:07.000656Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"File artifacts/labels/labels.json uploaded to written-number-classifier/artifact/label-artifact/labels.json\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## Fine Tuning","metadata":{"id":"26MxbISMDLhF"}},{"cell_type":"code","source":"# List available physical devices\nphysical_devices = tf.config.list_physical_devices()\nprint(\"Available physical devices:\", physical_devices)\n\n# Check specifically for GPUs\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    print(f\"GPUs detected: {gpus}\")\nelse:\n    print(\"No GPUs detected.\")\n","metadata":{"id":"llOY3zsqO0p4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4bfd3664-5cc3-46e7-9214-c89fc304a2e0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = tf.keras.applications.EfficientNetB7(\n    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n    input_shape=(256, 256, 3),\n    include_top=False,\n    pooling='average'\n)  # Do not include the ImageNet classifier at the top.\n\n# Freeze the base_model\nbase_model.trainable = False\n\n# Create new model on top\ninputs = tf.keras.Input(shape=(256, 256, 1))\n\n# The base model contains batchnorm layers. We want to keep them in inference mode\n# when we unfreeze the base model for fine-tuning, so we make sure that the\n# base_model is running in inference mode here.\nx = base_model(inputs,training=False)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n# x = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\noutputs = tf.keras.layers.Dense(100)(x)\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.summary(show_trainable=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PUoXEyw0vcx","outputId":"75d10ebb-577c-41f2-f91f-a234be09e872"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n)\n\n# Define the number of epochs\nepochs = 100\n\n# Set up TensorBoard callback with histogram_freq\ntensorboard_callback = TensorBoard(log_dir= TRAINING_LOG_DIR, histogram_freq=1)\n\n# Set up EarlyStopping callback\nearly_stopping_callback = EarlyStopping(\n    monitor='val_sparse_categorical_accuracy',  # Metric to monitor\n    patience=10,          # Number of epochs with no improvement after which training will be stopped\n    restore_best_weights=True  # Whether to restore model weights from the epoch with the best value of the monitored quantity\n)\n\n# Set up ModelCheckpoint callback with formatted filepath\ncheckpoint_callback = ModelCheckpoint(\n    filepath=os.path.join(CHECKPOINT_DIR,'{epoch:02d}-{val_loss:.2f}.h5'),  # Filepath to save the model\n    monitor='val_sparse_categorical_accuracy',  # Metric to monitor\n    save_best_only=True  # Save only the best model\n)\n\n# Set up ReduceLROnPlateau callback\nreduce_lr_callback = ReduceLROnPlateau(\n    monitor='val_sparse_categorical_accuracy',  # Metric to monitor\n    factor=0.2,  # Factor by which the learning rate will be reduced\n    patience=3,  # Number of epochs with no improvement after which learning rate will be reduced\n    min_lr=0.0001  # Lower bound on the learning rate\n)\n\n# Combine all callbacks\ncallbacks = [tensorboard_callback, early_stopping_callback, checkpoint_callback, reduce_lr_callback]\n\n# Ensure the checkpoint and log directory exists\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\nos.makedirs(TRAINING_LOG_DIR, exist_ok=True)\n\n# To start TensorBoard, run the following command in your terminal:\n# tensorboard --logdir=./logs\n","metadata":{"id":"5EZGO2tKhl_A","execution":{"iopub.status.busy":"2024-05-22T10:49:45.354719Z","iopub.execute_input":"2024-05-22T10:49:45.355522Z","iopub.status.idle":"2024-05-22T10:49:45.392601Z","shell.execute_reply.started":"2024-05-22T10:49:45.355479Z","shell.execute_reply":"2024-05-22T10:49:45.391736Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print(\"Fitting the top layer of the model\")\nmodel.fit(train_ds, epochs=epochs, validation_data=val_ds,callbacks=callbacks)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MjVQXO96LsXG","outputId":"94a07c33-5645-4995-aa3a-fd303f64981f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trainining stopped due colab GPU limit so best trained model is pushed to the S3 for reloading and training will restat from there using kaggle notebook","metadata":{"id":"fbI_vlhb1i_D"}},{"cell_type":"code","source":"# pushing the best model to S3\nupload_file_to_s3(file_name='/content/drive/MyDrive/written_number_classifier/model_checkpoints/10-2.29.keras',\n                  s3_resource=s3_resource,\n                  bucket_name='written-number-classifier',\n                  object_name='artifact/model-artiact/best_model.keras'\n                  )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mUWF9oht13tw","outputId":"52ee4bbf-e8db-43ee-8b6a-433df77a3d70","execution":{"iopub.status.busy":"2024-05-22T11:13:11.842328Z","iopub.execute_input":"2024-05-22T11:13:11.843127Z","iopub.status.idle":"2024-05-22T11:13:11.853240Z","shell.execute_reply.started":"2024-05-22T11:13:11.843093Z","shell.execute_reply":"2024-05-22T11:13:11.852153Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Error uploading file: [Errno 2] No such file or directory: '/content/drive/MyDrive/written_number_classifier/model_checkpoints/10-2.29.keras'\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"markdown","source":"## Restarting the training in kaggle by loading the best model till now from S3","metadata":{"id":"MsC4V0hu5JPW"}},{"cell_type":"code","source":"import keras\n# print(keras.__version__)\n# !pip install keras==2.15.0\nprint(keras.__version__)\n# !pip show tensorflow\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:29:09.516624Z","iopub.execute_input":"2024-05-22T11:29:09.517518Z","iopub.status.idle":"2024-05-22T11:29:09.522597Z","shell.execute_reply.started":"2024-05-22T11:29:09.517486Z","shell.execute_reply":"2024-05-22T11:29:09.521517Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"2.15.0\n2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# create model artifact directory\nos.makedirs(MODEL_ARTIFACT,exist_ok=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# downloading the model from s3\ndownload_file_from_s3(\n    s3_resource,\n    'written-number-classifier',\n    S3_MODEL_ARTIFACT_PATH,\n    os.path.join(MODEL_ARTIFACT,'working_model.keras')\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:27:07.774000Z","iopub.execute_input":"2024-05-22T11:27:07.774982Z","iopub.status.idle":"2024-05-22T11:27:13.653041Z","shell.execute_reply.started":"2024-05-22T11:27:07.774946Z","shell.execute_reply":"2024-05-22T11:27:13.651987Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"File artifact/model-artiact/best_model.keras from bucket written-number-classifier downloaded as artifacts/model/working_model.keras\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"## loading the model\nmodel = tf.keras.models.load_model(os.path.join(MODEL_ARTIFACT,'working_model.keras'))\n# model = tf.keras.models.load_model('/kaggle/working/model_checkpoints/11-0.97.keras')\n","metadata":{"id":"Xj_Vt9Hz3fjv","_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-22T11:27:27.707874Z","iopub.execute_input":"2024-05-22T11:27:27.708903Z","iopub.status.idle":"2024-05-22T11:27:38.678065Z","shell.execute_reply.started":"2024-05-22T11:27:27.708864Z","shell.execute_reply":"2024-05-22T11:27:38.677232Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"model.summary(show_trainable=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:50:40.521661Z","iopub.execute_input":"2024-05-22T09:50:40.522100Z","iopub.status.idle":"2024-05-22T09:50:40.617444Z","shell.execute_reply.started":"2024-05-22T09:50:40.522069Z","shell.execute_reply":"2024-05-22T09:50:40.616394Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n____________________________________________________________________________\n Layer (type)                Output Shape              Param #   Trainable  \n============================================================================\n input_4 (InputLayer)        [(None, 256, 256, 1)]     0         Y          \n                                                                            \n efficientnetb7 (Functional  (None, 8, 8, 2560)        6409768   Y          \n )                                                     7                    \n                                                                            \n global_average_pooling2d_1  (None, 2560)              0         Y          \n  (GlobalAveragePooling2D)                                                  \n                                                                            \n dense_1 (Dense)             (None, 100)               256100    Y          \n                                                                            \n============================================================================\nTotal params: 64353787 (245.49 MB)\nTrainable params: 256100 (1000.39 KB)\nNon-trainable params: 64097687 (244.51 MB)\n____________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(train_ds, epochs=epochs, validation_data=val_ds,callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pushing the best model to S3\nupload_file_to_s3(file_name='/kaggle/working/model_checkpoints/03-0.95.h5',\n                  s3_resource=s3_resource,\n                  bucket_name='written-number-classifier',\n                  object_name='artifact/model-artiact/best_model.h5'\n                  )","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:14:55.988135Z","iopub.execute_input":"2024-05-22T11:14:55.989114Z","iopub.status.idle":"2024-05-22T11:14:59.588206Z","shell.execute_reply.started":"2024-05-22T11:14:55.989075Z","shell.execute_reply":"2024-05-22T11:14:59.587290Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"File /kaggle/working/model_checkpoints/03-0.95.h5 uploaded to written-number-classifier/artifact/model-artiact/best_model.h5\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## Prparing the model for inferencing and pushing it s3 model registory","metadata":{}},{"cell_type":"code","source":"model = model = tf.keras.models.load_model('/kaggle/working/model_checkpoints/46-0.88.keras')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:57:45.309709Z","iopub.execute_input":"2024-05-22T12:57:45.310584Z","iopub.status.idle":"2024-05-22T12:58:54.956794Z","shell.execute_reply.started":"2024-05-22T12:57:45.310535Z","shell.execute_reply":"2024-05-22T12:58:54.955706Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# adding softmax layer to predict probablities of class labels\nprobability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n# saving model in local model registry\nprobability_model.save(MODEL_REGISTRY)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:59:16.659344Z","iopub.execute_input":"2024-05-22T12:59:16.660401Z","iopub.status.idle":"2024-05-22T12:59:21.056130Z","shell.execute_reply.started":"2024-05-22T12:59:16.660363Z","shell.execute_reply":"2024-05-22T12:59:21.054978Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# pushing the prod model to S3 remote registry\nupload_file_to_s3(file_name=MODEL_REGISTRY,\n                  s3_resource=s3_resource,\n                  bucket_name='written-number-classifier',\n                  object_name=MODEL_REGISTRY\n                  )","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:59:30.042626Z","iopub.execute_input":"2024-05-22T12:59:30.043416Z","iopub.status.idle":"2024-05-22T12:59:33.435984Z","shell.execute_reply.started":"2024-05-22T12:59:30.043383Z","shell.execute_reply":"2024-05-22T12:59:33.434897Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"File model_registry/prod_model.h5 uploaded to written-number-classifier/model_registry/prod_model.h5\n","output_type":"stream"},{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## Testing inference","metadata":{}},{"cell_type":"code","source":"import keras\nprint(keras.__version__)","metadata":{"id":"SiumqINt5Gsf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip show tensorflow","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n\nimage = tf.keras.utils.load_img(\n                    path=Path(\"/kaggle/working/artifacts/feature_store/test/forty six/image_93.png\"),\n                    color_mode='grayscale',\n                    target_size=(256,256,1),\n                    interpolation='nearest'\n                    )\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:46:44.225588Z","iopub.execute_input":"2024-05-22T09:46:44.226058Z","iopub.status.idle":"2024-05-22T09:46:44.236964Z","shell.execute_reply.started":"2024-05-22T09:46:44.226020Z","shell.execute_reply":"2024-05-22T09:46:44.236066Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"image","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:46:55.491586Z","iopub.execute_input":"2024-05-22T09:46:55.491986Z","iopub.status.idle":"2024-05-22T09:46:55.500810Z","shell.execute_reply.started":"2024-05-22T09:46:55.491956Z","shell.execute_reply":"2024-05-22T09:46:55.499437Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<PIL.Image.Image image mode=L size=256x256>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"image=np.array(image).reshape(1,256,256,1)\nimage","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:47:05.402295Z","iopub.execute_input":"2024-05-22T09:47:05.403023Z","iopub.status.idle":"2024-05-22T09:47:05.411511Z","shell.execute_reply.started":"2024-05-22T09:47:05.402988Z","shell.execute_reply":"2024-05-22T09:47:05.410456Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array([[[[255],\n         [255],\n         [255],\n         ...,\n         [255],\n         [255],\n         [255]],\n\n        [[255],\n         [255],\n         [255],\n         ...,\n         [255],\n         [255],\n         [255]],\n\n        [[255],\n         [255],\n         [255],\n         ...,\n         [255],\n         [255],\n         [255]],\n\n        ...,\n\n        [[255],\n         [255],\n         [255],\n         ...,\n         [255],\n         [255],\n         [255]],\n\n        [[255],\n         [255],\n         [255],\n         ...,\n         [255],\n         [255],\n         [255]],\n\n        [[255],\n         [255],\n         [255],\n         ...,\n         [255],\n         [255],\n         [255]]]], dtype=uint8)"},"metadata":{}}]},{"cell_type":"code","source":"pred = probability_model.predict(image)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:28:22.969021Z","iopub.execute_input":"2024-05-22T11:28:22.969697Z","iopub.status.idle":"2024-05-22T11:28:28.058700Z","shell.execute_reply.started":"2024-05-22T11:28:22.969660Z","shell.execute_reply":"2024-05-22T11:28:28.057859Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 5s 5s/step\n","output_type":"stream"}]},{"cell_type":"code","source":"pred_idx = np.argmax(pred)\ntype(pred_idx)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:28:31.997457Z","iopub.execute_input":"2024-05-22T11:28:31.997831Z","iopub.status.idle":"2024-05-22T11:28:32.004662Z","shell.execute_reply.started":"2024-05-22T11:28:31.997805Z","shell.execute_reply":"2024-05-22T11:28:32.003639Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"numpy.int64"},"metadata":{}}]},{"cell_type":"code","source":"class_labels = read_class_labels(LABEL_ARTIFACT)\nprint(class_labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:36:45.316224Z","iopub.execute_input":"2024-05-22T10:36:45.316989Z","iopub.status.idle":"2024-05-22T10:36:45.322358Z","shell.execute_reply.started":"2024-05-22T10:36:45.316957Z","shell.execute_reply":"2024-05-22T10:36:45.321423Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"{'0': 'eight', '1': 'eighteen', '2': 'eighty', '3': 'eighty eight', '4': 'eighty five', '5': 'eighty four', '6': 'eighty nine', '7': 'eighty one', '8': 'eighty seven', '9': 'eighty six', '10': 'eighty three', '11': 'eighty two', '12': 'eleven', '13': 'fifteen', '14': 'fifty', '15': 'fifty eight', '16': 'fifty five', '17': 'fifty four', '18': 'fifty nine', '19': 'fifty one', '20': 'fifty seven', '21': 'fifty six', '22': 'fifty three', '23': 'fifty two', '24': 'five', '25': 'forty', '26': 'forty eight', '27': 'forty five', '28': 'forty four', '29': 'forty nine', '30': 'forty one', '31': 'forty seven', '32': 'forty six', '33': 'forty three', '34': 'forty two', '35': 'four', '36': 'fourteen', '37': 'hundred', '38': 'nine', '39': 'nineteen', '40': 'ninety', '41': 'ninety eight', '42': 'ninety five', '43': 'ninety four', '44': 'ninety nine', '45': 'ninety one', '46': 'ninety seven', '47': 'ninety six', '48': 'ninety three', '49': 'ninety two', '50': 'one', '51': 'seven', '52': 'seventeen', '53': 'seventy', '54': 'seventy eight', '55': 'seventy five', '56': 'seventy four', '57': 'seventy nine', '58': 'seventy one', '59': 'seventy seven', '60': 'seventy six', '61': 'seventy three', '62': 'seventy two', '63': 'six', '64': 'sixteen', '65': 'sixty', '66': 'sixty eight', '67': 'sixty five', '68': 'sixty four', '69': 'sixty nine', '70': 'sixty one', '71': 'sixty seven', '72': 'sixty six', '73': 'sixty three', '74': 'sixty two', '75': 'ten', '76': 'thirteen', '77': 'thirty', '78': 'thirty eight', '79': 'thirty five', '80': 'thirty four', '81': 'thirty nine', '82': 'thirty one', '83': 'thirty seven', '84': 'thirty six', '85': 'thirty three', '86': 'thirty two', '87': 'three', '88': 'twelve', '89': 'twenty', '90': 'twenty eight', '91': 'twenty five', '92': 'twenty four', '93': 'twenty nine', '94': 'twenty one', '95': 'twenty seven', '96': 'twenty six', '97': 'twenty three', '98': 'twenty two', '99': 'two'}\n","output_type":"stream"}]},{"cell_type":"code","source":"class_labels[str(pred_idx)]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:28:37.121958Z","iopub.execute_input":"2024-05-22T11:28:37.122765Z","iopub.status.idle":"2024-05-22T11:28:37.129004Z","shell.execute_reply.started":"2024-05-22T11:28:37.122731Z","shell.execute_reply":"2024-05-22T11:28:37.127895Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"'forty six'"},"metadata":{}}]},{"cell_type":"code","source":"!python --version","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:40:37.721946Z","iopub.execute_input":"2024-05-22T11:40:37.722379Z","iopub.status.idle":"2024-05-22T11:40:38.777230Z","shell.execute_reply.started":"2024-05-22T11:40:37.722346Z","shell.execute_reply":"2024-05-22T11:40:38.775880Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Python 3.10.13\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'model_registry/prod_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T13:01:04.007670Z","iopub.execute_input":"2024-05-22T13:01:04.008659Z","iopub.status.idle":"2024-05-22T13:01:04.014734Z","shell.execute_reply.started":"2024-05-22T13:01:04.008622Z","shell.execute_reply":"2024-05-22T13:01:04.013744Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/model_registry/prod_model.h5","text/html":"<a href='model_registry/prod_model.h5' target='_blank'>model_registry/prod_model.h5</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"FileLink(r'artifacts/labels/labels.json')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T12:29:07.324422Z","iopub.execute_input":"2024-05-22T12:29:07.325196Z","iopub.status.idle":"2024-05-22T12:29:07.331470Z","shell.execute_reply.started":"2024-05-22T12:29:07.325160Z","shell.execute_reply":"2024-05-22T12:29:07.330408Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/artifacts/labels/labels.json","text/html":"<a href='artifacts/labels/labels.json' target='_blank'>artifacts/labels/labels.json</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}}]}